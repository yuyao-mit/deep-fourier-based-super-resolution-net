
The following have been reloaded with a version change:
  1) python3/3.7.0 => python3/3.9.2

[rank: 5] Seed set to 42
[rank: 3] Seed set to 42
[rank: 1] Seed set to 42
[rank: 2] Seed set to 42
[rank: 0] Seed set to 42
[rank: 6] Seed set to 42
[rank: 4] Seed set to 42
[rank: 7] Seed set to 42
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 8 processes
----------------------------------------------------------------------------------------------------

/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /work2/10214/yu_yao/frontera/deepfaker/src/ckpt exists and is not empty.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name    | Type              | Params | Mode 
------------------------------------------------------
0 | model   | VRES_CNN_64to1024 | 315 M  | train
1 | loss_fn | MSELoss           | 0      | train
------------------------------------------------------
315 M     Trainable params
0         Non-trainable params
315 M     Total params
1,261.912 Total estimated model params size (MB)
52        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b46ae7d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b46ae7836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b46ae6f0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b46ae6f0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b467a7aa9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b467a7b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b4663cb4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b46ae7ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b46ae7b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b46ae7b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b4663f7aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b4663f7adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b46ae7d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b46ae7836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b46ae6f0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b46ae6f0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b467a7aa9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b467a7b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b4663cb4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b46ae7ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b3e95a12446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b3e959bc6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3e95929a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():    what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2affa3fc6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2affa3f706e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2affa3edda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3e95929d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b3e619e39a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3e619ec735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b3e4aeed630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b3e959f369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b3e959ec37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3e959ec529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2affa3eddd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2aff6ff979a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2aff6ffa0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2aff594a1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2affa3fa769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2affa3fa037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2affa3fa0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b3e4b1b3a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b3e4b1b3dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b3e95a12446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aff59767a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aff59767dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2affa3fc6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b3e959bc6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3e95929a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3e95929d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b3e619e39a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3e619ec735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b3e4aeed630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2affa3f706e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2affa3edda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2affa3eddd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2aff6ff979a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2aff6ffa0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2aff594a1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b3e959f369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2affa3fa769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09e0209446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09e01b36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09e0120a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b373715c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b37371066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3737073a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09e0120d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b09ac1da9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b09ac1e3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b09956e4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b09e01ea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b09e01e337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b09e01e3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3737073d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b370312d9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3703136735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b36ec637630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b373713d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b373713637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3737136529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b09959aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b09959aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09e0209446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b36ec8fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b36ec8fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():    what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b373715c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09e01b36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09e0120a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09e0120d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b09ac1da9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b09ac1e3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b09956e4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b37371066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3737073a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3737073d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b370312d9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3703136735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b36ec637630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b09e01ea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b373713d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b31b58f6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b31b58a06e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b31b580da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():    what():    what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac983ccb446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac983c756e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac983be2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b31b580dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b31818c79a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b31818d0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b316add1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b31b58d769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b31b58d037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b31b58d0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac983be2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2ac94fc9c9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac94fca5735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac9391a6630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac983cac69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac983ca537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac983ca5529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b316b097a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b316b097dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b31b58f6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac93946ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac93946cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac983ccb446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b31b58a06e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b31b580da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b31b580dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b31818c79a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b31818d0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b316add1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac983c756e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac983be2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac983be2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2ac94fc9c9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac94fca5735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac9391a6630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b31b58d769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2ac983cac69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ba3fee0c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ba3fedb66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ba3fed23a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b46ae7b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b46ae7b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b4663f7aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b4663f7adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ba3fed23d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2ba3caddd9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ba3cade6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ba3b42e7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ba3feded69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ba3fede637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ba3fede6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2affa3fa037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2affa3fa0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aff59767a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aff59767dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #10: <unknown function> + 0x8c1a78 (0x2ba3b45ada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ba3b45addc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ba3fee0c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2affa3fc6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2affa3f706e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2affa3edda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2affa3eddd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2aff6ff979a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2aff6ffa0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ba3fedb66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ba3fed23a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ba3fed23d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2ba3caddd9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ba3cade6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ba3b42e7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x5fb630 (0x2aff594a1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2affa3fa769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2affa3fa037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2affa3fa0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aff59767a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aff59767dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
frame #7: <unknown function> + 0x6f69f (0x2ba3feded69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2affa3fc6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2affa3f706e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2affa3edda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b3e959ec37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3e959ec529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b3e4b1b3a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b3e4b1b3dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():    what():  

CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2affa3eddd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b3e95a12446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b3e959bc6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3e95929a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3e95929d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b3e619e39a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b373713637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3737136529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b36ec8fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b36ec8fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #5: <unknown function> + 0x102a735 (0x2b3e619ec735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b3e4aeed630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b3e959f369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b3e959ec37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3e959ec529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b3e4b1b3a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b3e4b1b3dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b373715c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b37371066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3737073a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3737073d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b370312d9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3703136735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b3e95a12446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b3e959bc6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3e95929a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b36ec637630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b373713d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b373713637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3737136529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b36ec8fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b36ec8fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3e95929d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b373715c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b37371066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b3737073a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b09e01e337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b09e01e3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b09959aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b09959aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b3737073d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09e0209446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09e01b36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09e0120a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09e0120d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b09ac1da9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b09ac1e3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac983ca537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac983ca5529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac93946ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac93946cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b09956e4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b09e01ea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b09e01e337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b09e01e3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b09959aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b09959aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>



  what():  CUDA error: initialization error
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac983ccb446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac983c756e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac983be2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac983be2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2ac94fc9c9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac94fca5735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09e0209446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09e01b36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09e0120a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac9391a6630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac983cac69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac983ca537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac983ca5529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac93946ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac93946cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09e0120d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac983ccb446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac983c756e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac983be2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b31b58d037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b31b58d0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b316b097a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b316b097dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac983be2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b31b58f6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b31b58a06e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b31b580da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b31b580dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b31818c79a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2aff6ff979a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2aff6ffa0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2aff594a1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2affa3fa769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2affa3fa037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2affa3fa0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aff59767a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #5: <unknown function> + 0x102a735 (0x2b31818d0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b316add1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b31b58d769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b31b58d037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b31b58d0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b316b097a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b316b097dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aff59767dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>



<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b31b58f6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b31b58a06e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b31b580da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b370312d9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3703136735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b36ec637630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b373713d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b373713637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3737136529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b36ec8fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b31b580dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b36ec8fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>



frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ba3fede637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ba3fede6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ba3b45ada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ba3b45addc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #4: <unknown function> + 0x10219a0 (0x2ac94fc9c9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac94fca5735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac9391a6630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac983cac69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac983ca537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac983ca5529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac93946ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ba3fee0c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ba3fedb66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ba3fed23a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ba3fed23d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2ba3caddd9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ba3cade6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac93946cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>




frame #6: <unknown function> + 0x5fb630 (0x2ba3b42e7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ba3feded69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ba3fede637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ba3fede6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ba3b45ada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ba3b45addc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error

CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ba3fee0c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ba3fedb66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ba3fed23a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ba3fed23d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x10219a0 (0x2b3e619e39a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b3e619ec735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b3e4aeed630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b3e959f369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b3e959ec37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b3e959ec529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b3e4b1b3a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b3e4b1b3dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #4: <unknown function> + 0x10219a0 (0x2b09ac1da9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b09ac1e3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b09956e4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b09e01ea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b09e01e337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b09e01e3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b09959aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b09959aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #4: <unknown function> + 0x10219a0 (0x2b31818c79a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b31818d0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b316add1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b31b58d769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b31b58d037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b31b58d0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b316b097a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b316b097dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>



frame #4: <unknown function> + 0x10219a0 (0x2ba3caddd9a0 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ba3cade6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ba3b42e7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ba3feded69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ba3fede637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ba3fede6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ba3b45ada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ba3b45addc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


[rank1]: Traceback (most recent call last):
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank1]:     data = self._data_queue.get(timeout=timeout)
[rank1]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank1]:     self.not_empty.wait(remaining)
[rank1]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank1]:     gotit = waiter.acquire(True, timeout)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank1]:     _error_if_any_worker_fails()
[rank1]: RuntimeError: DataLoader worker (pid 32767) is killed by signal: Aborted. 

[rank1]: The above exception was the direct cause of the following exception:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank1]:     main(
[rank1]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank1]:     trainer.fit(
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank1]:     self.advance()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank1]:     batch, _, __ = next(data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank1]:     batch = super().__next__()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank1]:     batch = next(self.iterator)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank1]:     out = next(self._iterator)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank1]:     out[i] = next(self.iterators[i])
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank1]:     data = self._next_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank1]:     idx, data = self._get_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank1]:     success, data = self._try_get_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank1]:     raise RuntimeError(
[rank1]: RuntimeError: DataLoader worker (pid(s) 32761, 32765, 32767, 302) exited unexpectedly
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank5]:     data = self._data_queue.get(timeout=timeout)
[rank5]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank5]:     self.not_empty.wait(remaining)
[rank5]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank5]:     gotit = waiter.acquire(True, timeout)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank5]:     _error_if_any_worker_fails()
[rank5]: RuntimeError: DataLoader worker (pid 21970) is killed by signal: Aborted. 

[rank5]: The above exception was the direct cause of the following exception:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank5]:     main(
[rank5]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank5]:     trainer.fit(
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank5]:     call._call_and_handle_interrupt(
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank5]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank5]:     self._run(model, ckpt_path=ckpt_path)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank5]:     results = self._run_stage()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank5]:     self.fit_loop.run()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank5]:     self.advance()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank5]:     self.epoch_loop.run(self._data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank5]:     self.advance(data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank5]:     batch, _, __ = next(data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank5]:     batch = super().__next__()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank5]:     batch = next(self.iterator)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank5]:     out = next(self._iterator)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank5]:     out[i] = next(self.iterators[i])
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank5]:     data = self._next_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank5]:     idx, data = self._get_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank5]:     success, data = self._try_get_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank5]:     raise RuntimeError(
[rank5]: RuntimeError: DataLoader worker (pid(s) 21956, 21960, 21965, 21970) exited unexpectedly
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank7]:     data = self._data_queue.get(timeout=timeout)
[rank7]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank7]:     self.not_empty.wait(remaining)
[rank7]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank7]:     gotit = waiter.acquire(True, timeout)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank7]:     _error_if_any_worker_fails()
[rank7]: RuntimeError: DataLoader worker (pid 21966) is killed by signal: Aborted. 

[rank7]: The above exception was the direct cause of the following exception:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank7]:     main(
[rank7]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank7]:     trainer.fit(
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank7]:     call._call_and_handle_interrupt(
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank7]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank7]:     self._run(model, ckpt_path=ckpt_path)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank7]:     results = self._run_stage()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank7]:     self.fit_loop.run()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank7]:     self.advance()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank7]:     self.epoch_loop.run(self._data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank7]:     self.advance(data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank7]:     batch, _, __ = next(data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank7]:     batch = super().__next__()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank7]:     batch = next(self.iterator)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank7]:     out = next(self._iterator)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank7]:     out[i] = next(self.iterators[i])
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank7]:     data = self._next_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank7]:     idx, data = self._get_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank7]:     success, data = self._try_get_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank7]:     raise RuntimeError(
[rank7]: RuntimeError: DataLoader worker (pid(s) 21958, 21962, 21966, 21973) exited unexpectedly
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank4]:     data = self._data_queue.get(timeout=timeout)
[rank4]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank4]:     self.not_empty.wait(remaining)
[rank4]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank4]:     gotit = waiter.acquire(True, timeout)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank4]:     _error_if_any_worker_fails()
[rank4]: RuntimeError: DataLoader worker (pid 21963) is killed by signal: Aborted. 

[rank4]: The above exception was the direct cause of the following exception:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank4]:     main(
[rank4]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank4]:     trainer.fit(
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank4]:     call._call_and_handle_interrupt(
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank4]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank4]:     self._run(model, ckpt_path=ckpt_path)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank4]:     results = self._run_stage()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank4]:     self.fit_loop.run()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank4]:     self.advance()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank4]:     self.epoch_loop.run(self._data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank4]:     self.advance(data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank4]:     batch, _, __ = next(data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank4]:     batch = super().__next__()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank4]:     batch = next(self.iterator)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank4]:     out = next(self._iterator)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank4]:     out[i] = next(self.iterators[i])
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank4]:     data = self._next_data()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank4]:     idx, data = self._get_data()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank4]:     success, data = self._try_get_data()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank4]:     raise RuntimeError(
[rank4]: RuntimeError: DataLoader worker (pid(s) 21955, 21959, 21963, 21967) exited unexpectedly
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank6]:     data = self._data_queue.get(timeout=timeout)
[rank6]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank6]:     self.not_empty.wait(remaining)
[rank6]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank6]:     gotit = waiter.acquire(True, timeout)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank6]:     _error_if_any_worker_fails()
[rank6]: RuntimeError: DataLoader worker (pid 21964) is killed by signal: Aborted. 

[rank6]: The above exception was the direct cause of the following exception:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank6]:     main(
[rank6]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank6]:     trainer.fit(
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank6]:     call._call_and_handle_interrupt(
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank6]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank6]:     self._run(model, ckpt_path=ckpt_path)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank6]:     results = self._run_stage()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank6]:     self.fit_loop.run()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank6]:     self.advance()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank6]:     self.epoch_loop.run(self._data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank6]:     self.advance(data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank6]:     batch, _, __ = next(data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank6]:     batch = super().__next__()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank6]:     batch = next(self.iterator)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank6]:     out = next(self._iterator)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank6]:     out[i] = next(self.iterators[i])
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank6]:     data = self._next_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank6]:     idx, data = self._get_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank6]:     success, data = self._try_get_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank6]:     raise RuntimeError(
[rank6]: RuntimeError: DataLoader worker (pid(s) 21957, 21961, 21964, 21969) exited unexpectedly
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank0]:     data = self._data_queue.get(timeout=timeout)
[rank0]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank0]:     self.not_empty.wait(remaining)
[rank0]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank0]:     gotit = waiter.acquire(True, timeout)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank0]:     _error_if_any_worker_fails()
[rank0]: RuntimeError: DataLoader worker (pid 32759) is killed by signal: Aborted. 

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank0]:     main(
[rank0]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank0]:     trainer.fit(
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank0]:     self.advance()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank0]:     batch, _, __ = next(data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank0]:     batch = super().__next__()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank0]:     batch = next(self.iterator)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank0]:     out = next(self._iterator)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank0]:     out[i] = next(self.iterators[i])
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank0]:     idx, data = self._get_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank0]:     success, data = self._try_get_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank0]:     raise RuntimeError(
[rank0]: RuntimeError: DataLoader worker (pid(s) 32759, 32764) exited unexpectedly
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank2]:     data = self._data_queue.get(timeout=timeout)
[rank2]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank2]:     self.not_empty.wait(remaining)
[rank2]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank2]:     gotit = waiter.acquire(True, timeout)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank2]:     _error_if_any_worker_fails()
[rank2]: RuntimeError: DataLoader worker (pid 306) is killed by signal: Aborted. 

[rank2]: The above exception was the direct cause of the following exception:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank2]:     main(
[rank2]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank2]:     trainer.fit(
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank2]:     self.advance()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank2]:     batch, _, __ = next(data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank2]:     batch = super().__next__()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank2]:     batch = next(self.iterator)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank2]:     out = next(self._iterator)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank2]:     out[i] = next(self.iterators[i])
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank2]:     data = self._next_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank2]:     idx, data = self._get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank2]:     success, data = self._try_get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank2]:     raise RuntimeError(
[rank2]: RuntimeError: DataLoader worker (pid(s) 32762, 32766, 301, 306) exited unexpectedly
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank3]:     data = self._data_queue.get(timeout=timeout)
[rank3]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank3]:     self.not_empty.wait(remaining)
[rank3]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank3]:     gotit = waiter.acquire(True, timeout)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank3]:     _error_if_any_worker_fails()
[rank3]: RuntimeError: DataLoader worker (pid 304) is killed by signal: Aborted. 

[rank3]: The above exception was the direct cause of the following exception:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank3]:     main(
[rank3]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank3]:     trainer.fit(
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank3]:     self.advance()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank3]:     batch, _, __ = next(data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank3]:     batch = super().__next__()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank3]:     batch = next(self.iterator)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank3]:     out = next(self._iterator)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank3]:     out[i] = next(self.iterators[i])
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank3]:     data = self._next_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank3]:     idx, data = self._get_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank3]:     success, data = self._try_get_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank3]:     raise RuntimeError(
[rank3]: RuntimeError: DataLoader worker (pid(s) 32760, 32763, 300, 304) exited unexpectedly
srun: error: c197-092: tasks 4-7: Exited with exit code 1
srun: error: c197-091: tasks 0-3: Exited with exit code 1
